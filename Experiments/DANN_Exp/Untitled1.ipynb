{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import sys, os\n",
    "sys.path.append('../..')\n",
    "from Data.ABSALoader import Senti_domain_map, ABSA_Dataset\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from BaseModel.ABSAModel import ABSA_BERT, DomainDiscriminator\n",
    "from DomainAdaptationTrainer.DANN import DANNTrainer,GpDANNTrainer\n",
    "import random, numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from TrainingEnv import GradientReversal"
   ],
   "id": "c6ca66e756b1a231",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "class DANN_ABSA_Model(ABSA_BERT):\n",
    "    def AdvDLossAndAcc(self, discriminator: nn.Module, batch, grad_reverse=False):\n",
    "        f = self.Batch2Vecs(batch)\n",
    "        if grad_reverse:\n",
    "            f = GradientReversal.apply(f)\n",
    "        predictions = discriminator(self.dropout(f)).softmax(dim=1)\n",
    "        epsilon = torch.ones_like(predictions) * 1e-8\n",
    "        preds = (\n",
    "                    predictions - epsilon).abs()  # to avoid the prediction [1.0, 0.0], which leads to the 'nan' value in log operation\n",
    "        labels = batch[-1]\n",
    "        loss, acc = self.loss_func(preds, labels, label_weight=None, reduction='mean')\n",
    "        return loss, acc\n",
    "\n",
    "    def grouped_parameters(self, learning_rate):\n",
    "        def lr_coefficient(par_name):\n",
    "        # layer-wise fine-tuning\n",
    "            if \"layer.\" in par_name:\n",
    "                layer_num = int(par_name.split(\"layer.\")[1].split(\".\", 1)[0])\n",
    "                return pow(0.8, 12 - layer_num)\n",
    "            elif \"embedding\" in par_name:\n",
    "                return pow(0.8, 13)\n",
    "            else:\n",
    "                return 1.0\n",
    "        if learning_rate is None:\n",
    "            learning_rate = self.learning_rate\n",
    "        optimizerGroupedParameters = [{'params': p, 'lr': learning_rate * lr_coefficient(n)}\n",
    "                                        for n, p in self.named_parameters()]\n",
    "        return optimizerGroupedParameters\n",
    "\n",
    "\n",
    "def obtain_model(bertPath, model_device, lr_model, lr_D):\n",
    "    bert_config = BertConfig.from_pretrained(bertPath, num_labels=3)\n",
    "    tokenizer_M = BertTokenizer.from_pretrained(bertPath)\n",
    "    bert_config.num_labels = 3\n",
    "    bert_config.hidden_act = \"relu\"\n",
    "    tokenizer_M.model_max_length = 256\n",
    "    # Create the model\n",
    "    bert = DANN_ABSA_Model.from_pretrained(bertPath, config=bert_config).to(model_device)\n",
    "    bert.learning_rate = lr_model\n",
    "    discriminator = DomainDiscriminator(hidden_size=bert_config.hidden_size,\n",
    "                                        model_device=model_device,\n",
    "                                        learningRate=lr_D,\n",
    "                                        domain_num=3)\n",
    "    return bert, tokenizer_M, discriminator\n",
    "\n",
    "\n",
    "def obtain_domain_set(new_domain_name, tokenizer_M, database_name, few_shot_cnt=100):\n",
    "    domain_set = set(Senti_domain_map)\n",
    "    domain_set.remove(new_domain_name)\n",
    "    source_domain = ABSA_Dataset(\n",
    "        database_name=database_name,\n",
    "        seen_domains=list(domain_set),\n",
    "        table_name_list=['Train'],\n",
    "        tokenizer=tokenizer_M,\n",
    "        max_data_size=-1,\n",
    "        C_dimension=3,\n",
    "        load_data=True\n",
    "    )\n",
    "    test_target = ABSA_Dataset(\n",
    "        database_name=database_name,\n",
    "        seen_domains=[new_domain_name],\n",
    "        table_name_list=['Test'],\n",
    "        tokenizer=tokenizer_M,\n",
    "        max_data_size=-1,\n",
    "        C_dimension=3,\n",
    "        load_data=True\n",
    "    )\n",
    "    unlabeled_target = ABSA_Dataset(\n",
    "        database_name=database_name,\n",
    "        seen_domains=[new_domain_name],\n",
    "        table_name_list=['Train'],\n",
    "        tokenizer=tokenizer_M,\n",
    "        max_data_size=-1,\n",
    "        C_dimension=3,\n",
    "        load_data=True\n",
    "    )\n",
    "    val_idxs = random.sample(range(len(unlabeled_target)),\n",
    "                             int(0.2 * len(unlabeled_target)))\n",
    "    val_set = unlabeled_target.Derive(idxs=val_idxs)\n",
    "    if few_shot_cnt > 0:\n",
    "        labeled_target = ABSA_Dataset(\n",
    "            database_name=database_name,\n",
    "            seen_domains=[new_domain_name],\n",
    "            table_name_list=['FewShot'],\n",
    "            tokenizer=tokenizer_M,\n",
    "            max_data_size=few_shot_cnt,\n",
    "            C_dimension=3,\n",
    "            load_data=True\n",
    "        )\n",
    "        return source_domain, val_set, test_target, labeled_target, unlabeled_target\n",
    "    else:\n",
    "        return source_domain, val_set, test_target, None, unlabeled_target\n",
    "\n",
    "\n",
    "def RunTask(domainID, fewShotCnt, logDir, bert_path, database_name=\"./DA_ASBA.db\"):\n",
    "    SentiDomainList = list(Senti_domain_map.keys())\n",
    "    print(\"SentiDomainList\",SentiDomainList)\n",
    "    newDomainName = SentiDomainList[domainID]\n",
    "    model1, tokenizer_M, discriminator = obtain_model(\n",
    "        bert_path,\n",
    "        torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "        lr_model=5e-5,\n",
    "        lr_D=5e-5\n",
    "    )\n",
    "    model1 = model1.cuda()\n",
    "    source_domain, val_set, test_target, labeled_target, unlabeled_target = obtain_domain_set(\n",
    "        newDomainName,\n",
    "        tokenizer_M,\n",
    "        database_name,\n",
    "        few_shot_cnt=fewShotCnt\n",
    "    )\n",
    "    TestLabel = test_target.labelTensor()\n",
    "    print(\"TestLabel : \", TestLabel.tolist())\n",
    "    unlabeled_target.setLabel(np.zeros_like(unlabeled_target.label),\n",
    "                              list(range(len(unlabeled_target))))\n",
    "    print(\"Zero ULabel : \", unlabeled_target.label.tolist())\n",
    "    trainer = GpDANNTrainer(random_seed=10086, log_dir=logDir, suffix=f\"{newDomainName}_FS{fewShotCnt}\",\n",
    "                          model_file=f\"./GpDANN_{newDomainName}_FS{fewShotCnt}.pkl\",\n",
    "                          class_num=3, temperature=0.05, learning_rate=2e-5, batch_size=32,\n",
    "                          Lambda=0.1)\n",
    "    trainer.collate_fn = val_set.collate_raw_batch\n",
    "\n",
    "    # Pretrain Task-specific Model\n",
    "    if os.path.exists(f\"./PreTrainClassifier_T{newDomainName}.pkl\"):\n",
    "        model1.load_state_dict(\n",
    "            torch.load(f\"./PreTrainClassifier_T{newDomainName}.pkl\")\n",
    "        )\n",
    "    else:\n",
    "        trainer.training(model1, source_domain, batch_size=28, max_epoch=20, lr4model=2e-5,\n",
    "                         dev_evaluator=None, test_evaluator=None,\n",
    "                         grad_accum_cnt=1, valid_every=100, model_path=f\"./PreTrainClassifier_T{newDomainName}.pkl\")\n",
    "        if os.path.exists(f\"./PreTrainClassifier_T{newDomainName}.pkl\"):\n",
    "            model1.load_state_dict(\n",
    "                torch.load(f\"./PreTrainClassifier_T{newDomainName}.pkl\")\n",
    "            )\n",
    "        else:\n",
    "            torch.save(model1.state_dict(),\n",
    "                       f\"./PreTrainClassifier_T{newDomainName}.pkl\")\n",
    "\n",
    "    trainer.valid(model1, val_set, val_set.labelTensor(), True, f\"{trainer.suffix}_valid\")\n",
    "    trainer.valid(model1, test_target, TestLabel, True, f\"{trainer.suffix}_test\")\n",
    "\n",
    "    trainer.ModelTrain(model1, discriminator, source_domain, labeled_target, unlabeled_target, val_set, test_target,\n",
    "                       maxEpoch=20, validEvery=20)\n"
   ],
   "id": "13f6a2650e90a534",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "    logDir = \"./LusTest\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    # logDir = \"OnlineTest\"\n",
    "    if not os.path.exists(logDir):\n",
    "        os.system(\"mkdir %s\" % logDir)\n",
    "    else:\n",
    "        os.system(\"rm -rf %s\" % logDir)\n",
    "        os.system(\"mkdir %s\" % logDir)\n",
    "    if not os.path.exists(\"./Caches/\"):\n",
    "        os.system(\"mkdir Caches\")\n",
    "    domainID = 2\n",
    "    fewShotCnt = 100\n",
    "    bert_path='../../../bert_en/' \n",
    "    database_name=\"../../Data/ABSA_Utils/ABSA.db\""
   ],
   "id": "3287733494e221db",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "    SentiDomainList = list(Senti_domain_map.keys())\n",
    "    print(\"SentiDomainList\",SentiDomainList)\n",
    "    newDomainName = SentiDomainList[domainID]\n",
    "    model1, tokenizer_M, discriminator = obtain_model(\n",
    "        bert_path,\n",
    "        torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "        lr_model=5e-5,\n",
    "        lr_D=5e-5\n",
    "    )\n",
    "    model1 = model1.cuda()"
   ],
   "id": "f147d93bbe406369",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "    source_domain, val_set, test_target, labeled_target, unlabeled_target = obtain_domain_set(\n",
    "        newDomainName,\n",
    "        tokenizer_M,\n",
    "        database_name,\n",
    "        few_shot_cnt=fewShotCnt\n",
    "    )\n",
    "    TestLabel = test_target.labelTensor()\n",
    "    print(\"TestLabel : \", TestLabel.tolist())\n",
    "    unlabeled_target.setLabel(np.zeros_like(unlabeled_target.label),\n",
    "                              list(range(len(unlabeled_target))))\n",
    "    print(\"Zero ULabel : \", unlabeled_target.label.tolist())"
   ],
   "id": "990a65e66fb7ae24",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "id": "a48099a9b49e6f66",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "id": "f1229b731a65c4f0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "id": "7ae6c0da1da20c3a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
